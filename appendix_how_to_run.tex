\definecolor{codebg}{RGB}{248,248,248}
\definecolor{codeframe}{RGB}{200,200,200}
\definecolor{codekeyword}{RGB}{0,112,32}
\definecolor{codestring}{RGB}{186,33,33}
\definecolor{codecomment}{RGB}{96,96,96}
\definecolor{codenumber}{RGB}{64,128,128}

\lstset{
    basicstyle=\ttfamily\small,
    backgroundcolor=\color{codebg},
    frame=single,
    rulecolor=\color{codeframe},
    framesep=3pt,
    xleftmargin=6pt,
    xrightmargin=6pt,
    breaklines=true,
    breakatwhitespace=true,
    showstringspaces=false,
    tabsize=4,
    aboveskip=8pt,
    belowskip=4pt,
    keywordstyle=\color{codekeyword}\bfseries,
    stringstyle=\color{codestring},
    commentstyle=\color{codecomment}\itshape,
    numberstyle=\tiny\color{codenumber},
    morekeywords={python,git,pip,source,cd,from,import,dataclass,class,def,True,False,None,tuple,int,float,str,bool},
}
% ============================================================================

\chapter{How to Run the Code}
\label{appendix:code}

This appendix provides comprehensive instructions for running the software presented in this thesis. The \texttt{optimal\_stopping} software framework implements all algorithms, payoff structures, and stochastic processes described in the preceding chapters. The complete source code is available at:

\begin{center}
\url{https://github.com/Daniel-Souza7/thesis-new-files}
\end{center}

\section{Installation and Setup}
\label{sec:installation}

\subsection{System Requirements}
\vspace{-4pt}

The software requires the following minimum specifications:
\vspace{-4pt}
\begin{itemize}
    \setlength{\itemsep}{1pt}
    \item \textbf{Python:} Version 3.8 or higher (3.13 is recommended)
    \item \textbf{Memory:} 8 GB RAM minimum; 32+ GB recommended for high-dimensional runs ($d \geq 100$)
    \item \textbf{Storage:} 16 GB+ for pre-computed path datasets (optional)
    \item \textbf{GPU:} CUDA-compatible GPU (optional; for deep learning methods DOS and NLSM only)
\end{itemize}

\subsection{Installation Procedure}
\vspace{-4pt}

\begin{enumerate}
    \setlength{\itemsep}{2pt}
    \item \textbf{Clone the repository:}
    \vspace{-4pt}
    \begin{lstlisting}[language=bash]
git clone https://github.com/Daniel-Souza7/thesis-new-files.git
cd thesis-new-files
    \end{lstlisting}

    \vspace{-6pt}
    \item \textbf{Create a virtual environment (recommended):}
    \vspace{-4pt}
    \begin{lstlisting}[language=bash]
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
    \end{lstlisting}

    \vspace{-6pt}
    \item \textbf{Install dependencies:}
    \vspace{-4pt}
    \begin{lstlisting}[language=bash]
pip install -r requirements.txt
    \end{lstlisting}

    \vspace{-6pt}
    \item \textbf{Verify installation:}
    \vspace{-4pt}
    \begin{lstlisting}[language=Python]
python -c "from optimal_stopping.payoffs import list_payoffs; \
           print(f'Loaded {len(list_payoffs())} payoffs')"
    \end{lstlisting}
    \vspace{-4pt}
    Expected output: \texttt{Loaded 360 payoffs}
\end{enumerate}

\section{Configuration System}
\label{sec:config-system}
\vspace{-4pt}

The framework employs a declarative configuration system where all parameters are specified in \texttt{optimal\_stopping/run/configs.py}. Each configuration is defined as a Python dataclass with parameters specified as iterables, enabling automatic grid search over all parameter combinations.

\subsection{Default Configuration Parameters}
\label{subsec:default-params}
\vspace{-4pt}

Table~\ref{tab:default-params} summarizes all configuration parameters alongside their default values and references to thesis definitions. When building a configuration using \texttt{\_DefaultConfig()} without specifying a parameter, it falls back to its default value. Parameters are grouped by category for clarity.

\vspace{-4pt}
\begin{table}[htbp]
\centering
\caption{Core configuration parameters and their default values.}
\label{tab:default-params}
\vspace{-4pt}
\scriptsize
\begin{tabular}{llllll}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Symbol} & \textbf{Default} & \textbf{Ref.} & \textbf{Notes} \\
\midrule
\multicolumn{6}{l}{\textit{Algorithm Selection}} \\
\texttt{algos} & \texttt{str} & --- & \texttt{('RT','RLSM')} & \ref{sec:algorithms} & Algorithm names \\
\texttt{hidden\_size} & \texttt{int} & $K$ & \texttt{(None,)} & \ref{subsec:neuron_allocation} & \texttt{None} $\rightarrow$ heuristic \\
\texttt{activation} & \texttt{str} & $\sigma(\cdot)$ & \texttt{('leakyrelu',)} & \ref{subsec:activation} & \texttt{'relu','elu','tanh'} \\
\texttt{dropout} & \texttt{float} & --- & \texttt{(0.0,)} & \ref{subsec:regularization} & Dropout probability \\
\texttt{ridge\_coeff} & \texttt{float} & $\lambda$ & \texttt{(1e-3,)} & \ref{subsec:regularization} & L2 regularization \\
\texttt{train\_ITM\_only} & \texttt{bool} & --- & \texttt{(True,)} & \ref{subsec:itm_filtering} & Train on ITM paths \\
\texttt{use\_payoff\_as\_input} & \texttt{bool} & --- & \texttt{(False,)} & \ref{subsec:payoff_augmentation} & Payoff augmentation \\
\texttt{nb\_epochs} & \texttt{int} & --- & \texttt{(30,)} & \ref{subsec:deep_learning} & Epochs (DOS/NLSM) \\
\midrule
\multicolumn{6}{l}{\textit{Problem Specification}} \\
\texttt{payoffs} & \texttt{str} & --- & \texttt{('BskCall',)} & \ref{sec:payoffs} & Payoff structure \\
\texttt{stock\_models} & \texttt{str} & --- & \texttt{('BlackScholes',)} & \ref{sec:stock_models} & Stochastic model \\
\texttt{nb\_stocks} & \texttt{int} & $d$ & \texttt{(1,)} & \ref{subsec:dimension} & Number of assets \\
\midrule
\multicolumn{6}{l}{\textit{Market Parameters}} \\
\texttt{drift} & \texttt{float} & $r$ & \texttt{(0.08,)} & \ref{subsec:gbm} & Risk-free rate \\
\texttt{volatilities} & \texttt{float} & $\sigma$ & \texttt{(0.2,)} & \ref{subsec:gbm} & Volatility \\
\texttt{dividends} & \texttt{float} & $q$ & \texttt{(0.0,)} & \ref{subsec:gbm} & Dividend yield \\
\texttt{correlation} & \texttt{float} & $\rho$ & \texttt{(0.0,)} & \ref{subsec:correlation} & Cross-asset corr. \\
\texttt{spots} & \texttt{float} & $S_0$ & \texttt{(100,)} & \ref{subsec:option_params} & Initial price \\
\texttt{strikes} & \texttt{float} & $K$ & \texttt{(100,)} & \ref{subsec:option_params} & Strike price \\
\texttt{maturities} & \texttt{float} & $T$ & \texttt{(1,)} & \ref{subsec:option_params} & Maturity (years) \\
\midrule
\multicolumn{6}{l}{\textit{Simulation Parameters}} \\
\texttt{nb\_paths} & \texttt{int} & $m$ & \texttt{(8000000,)} & \ref{subsec:monte_carlo} & Monte Carlo paths \\
\texttt{nb\_dates} & \texttt{int} & $N$ & \texttt{(100,)} & \ref{subsec:time_discretization} & Exercise dates \\
\texttt{nb\_runs} & \texttt{int} & --- & \texttt{1} & --- & Repetitions \\
\texttt{dtype} & \texttt{str} & --- & \texttt{('float32',)} & \ref{subsec:float} & Precision \\
\midrule
\multicolumn{6}{l}{\textit{Stochastic Volatility (Heston/Rough Heston)}} \\
\texttt{mean} & \texttt{float} & $\theta$ & \texttt{(0.3,)} & \ref{subsec:heston} & Long-run variance \\
\texttt{speed} & \texttt{float} & $\kappa$ & \texttt{(0.15,)} & \ref{subsec:heston} & Mean reversion \\
\texttt{hurst} & \texttt{float} & $H$ & \texttt{(0.75,)} & \ref{subsec:rough_heston} & Hurst parameter \\
\bottomrule
\end{tabular}
\end{table}

\vspace{-4pt}
\begin{table}[htbp]
\centering
\caption{Barrier and path-dependent configuration parameters.}
\label{tab:barrier-params}
\vspace{-4pt}
\scriptsize
\begin{tabular}{llllll}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Symbol} & \textbf{Default} & \textbf{Ref.} & \textbf{Notes} \\
\midrule
\multicolumn{6}{l}{\textit{Barrier Options}} \\
\texttt{barriers} & \texttt{float} & $B$ & \texttt{(100000,)} & \ref{subsec:barriers} & Single barrier \\
\texttt{barriers\_up} & \texttt{float} & $B_U$ & \texttt{(100000,)} & \ref{subsec:double_barriers} & Upper barrier \\
\texttt{barriers\_down} & \texttt{float} & $B_L$ & \texttt{(1,)} & \ref{subsec:double_barriers} & Lower barrier \\
\texttt{use\_barrier\_as\_input} & \texttt{bool} & --- & \texttt{(False,)} & \ref{subsec:barrier_features} & Barrier augmentation \\
\midrule
\multicolumn{6}{l}{\textit{Rank-Based Payoffs}} \\
\texttt{k} & \texttt{int} & $k$ & \texttt{(2,)} & \ref{subsec:rank_payoffs} & Best/Worst of $k$ \\
\texttt{weights} & \texttt{tuple} & $w$ & \texttt{(None,)} & \ref{subsec:rank_payoffs} & Custom weights \\
\texttt{factors} & \texttt{tuple} & --- & \texttt{((1,1,1),)} & \ref{subsec:factors} & Asset weights \\
\midrule
\multicolumn{6}{l}{\textit{Step Barriers}} \\
\texttt{step\_param1} & \texttt{float} & $B(0)$ & \texttt{(None,)} & \ref{subsec:step_barriers} & Start level \\
\texttt{step\_param2} & \texttt{float} & $B(T)$ & \texttt{(None,)} & \ref{subsec:step_barriers} & End level \\
\texttt{step\_param3} & \texttt{float} & $B_L(0)$ & \texttt{(None,)} & \ref{subsec:step_barriers} & Lower start \\
\texttt{step\_param4} & \texttt{float} & $B_L(T)$ & \texttt{(None,)} & \ref{subsec:step_barriers} & Lower end \\
\midrule
\multicolumn{6}{l}{\textit{Path-Dependent}} \\
\texttt{use\_path} & \texttt{bool} & --- & \texttt{(False,)} & \ref{subsec:path_dependent} & Path tracking \\
\midrule
\multicolumn{6}{l}{\textit{Data Sources}} \\
\texttt{user\_data\_file} & \texttt{str} & --- & \texttt{None} & \ref{subsec:user_data} & CSV filename \\
\texttt{representations} & \texttt{str} & --- & \texttt{('TablePrice} & --- & Output format \\
& & & \texttt{Duration',)} & & \\
\bottomrule
\end{tabular}
\end{table}

\noindent\textbf{Important:} When \texttt{hidden\_size} is set to \texttt{None}, the RT algorithm uses the dimension-adaptive heuristic from Equation~\eqref{eq:neuron_heuristic}:
\begin{equation}
\label{eq:neuron_heuristic}
\begin{split}
K(d) = \max(2d, 5) \cdot \mathbbm{1}_{\{1 \le d \le 9\}} + 1.5d \cdot \mathbbm{1}_{\{10 \le d \le 49\}} + 1.4d \cdot \mathbbm{1}_{\{50 \le d \le 99\}} \\
+ 1.3d \cdot \mathbbm{1}_{\{100 \le d \le 249\}} + 1.25d \cdot \mathbbm{1}_{\{250 \le d \le 499\}} + 1.2d \cdot \mathbbm{1}_{\{d \ge 500\}}.
\end{split}
\end{equation}

\subsection{Configuration Structure}
\vspace{-4pt}

A minimal configuration is created by instantiating \texttt{\_DefaultConfig} with the desired parameter overrides:
\vspace{-2pt}
\begin{lstlisting}[language=Python]
# In optimal_stopping/run/configs.py

my_experiment = _DefaultConfig(
    # Algorithm selection
    algos=['RT', 'RLSM', 'LSM'],

    # Problem specification
    payoffs=['BasketCall', 'BasketPut'],
    stock_models=['BlackScholes'],
    nb_stocks=[5, 50],

    # Market parameters (override defaults)
    drift=[0.05],
    volatilities=[0.2],

    # Simulation parameters
    nb_paths=[100000],
    nb_dates=[100],
    nb_runs=5,

    # Algorithm hyperparameters
    hidden_size=[75],
    activation=['leakyrelu'],
    use_payoff_as_input=[True],
    train_ITM_only=[True],
)
\end{lstlisting}

\vspace{-2pt}
\noindent The configuration above generates $3 \times 2 \times 2 = 12$ experimental combinations (3 algorithms $\times$ 2 payoffs $\times$ 2 dimensions), each repeated 5 times (\texttt{nb\_runs}). This totals $12 \times 5 = 60$ Monte Carlo training runs and another $60$ independent evaluation runs, each with $\texttt{nb\_paths} = 100\,000$ paths.

\section{Running Experiments}
\label{sec:running}

\subsection{Basic Execution}
\vspace{-4pt}

Once a configuration is defined in \texttt{configs.py}, experiments are executed via the command line:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.run_algo --configs=my_experiment
\end{lstlisting}

\vspace{-4pt}
\noindent The results are automatically saved to \texttt{optimal\_stopping/run/results/my\_experiment.csv}.

\subsection{Results Aggregation}
\vspace{-4pt}

To aggregate results into an Excel file with summary statistics (recommended):
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.write_excel --configs=my_experiment
\end{lstlisting}

\vspace{-4pt}
\noindent This generates \texttt{my\_experiment\_summary.xlsx} containing mean prices, standard deviations, and execution times for each configuration. Only execute after obtaining results from \texttt{run\_algo}.

\subsection{Command-Line Options}
\vspace{-4pt}

The execution script supports several options for filtering and customization:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.run_algo --configs=my_experiment \
    --nb_jobs=8 \              # Parallel CPU workers
    --algos=RT,RLSM \          # Filter algorithms
    --nb_stocks=50 \           # Filter dimensions
    --path_gen_seed=42 \       # Reproducible paths
    --print_errors             # Show full error traces
\end{lstlisting}

\vspace{-4pt}
\noindent Multiple configurations can be run simultaneously:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.run_algo --configs=exp1,exp2,exp3
\end{lstlisting}

\section{Reproducing Thesis Results}
\label{sec:reproducing}
\vspace{-4pt}

This section provides instructions to reproduce the principal experimental results presented in Chapter~\ref{ch:results}. The experiments require pre-computed path datasets to ensure exact reproducibility. These datasets are available at:

\begin{center}
\vspace{-4pt}
\url{https://drive.google.com/drive/u/0/folders/1QVHAzgOZjcE3zN3rTba81LQ-GmGk5wWx}
\vspace{-2pt}
\end{center}

\noindent Download the required \texttt{.h5} files and place them in the \texttt{optimal\_stopping/data/user\_data/} folder. The framework reads these via \texttt{stock\_models=['UserData']} with the corresponding \texttt{user\_data\_file} parameter.

\noindent\textbf{Alternative:} To run experiments with freshly generated paths (without stored data), replace \texttt{stock\_models=['UserData']} with \texttt{stock\_models=['BlackScholes']} and remove the \texttt{user\_data\_file} parameter.

\subsection{Table~\ref{tab:dimensional}: Dimensional Scalability Benchmark}
\vspace{-4pt}

To reproduce the cross-algorithm benchmark across dimensions $d \in \{1, 2, 7, 50, 500\}$, the following datasets are required:

\vspace{-4pt}
\begin{table}[htbp]
\centering
\caption{Required datasets for Table~\ref{tab:dimensional}.}
\vspace{-4pt}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{File} & $\mathbf{d}$ & $\mathbf{m}$ & \textbf{Parameters} \\
\midrule
\texttt{BS\_1.h5} & 1 & 8M & $r=0.08$, $\sigma=0.2$, $T=1$ \\
\texttt{BS\_2.h5} & 2 & 8M & $r=0.08$, $\sigma=0.2$, $T=1$ \\
\texttt{BS\_7.h5} & 7 & 14M & $r=0.08$, $\sigma=0.2$, $T=1$ \\
\texttt{BS\_50.h5} & 50 & 10M & $r=0.08$, $\sigma=0.2$, $T=1$ \\
\texttt{BS\_500.h5} & 500 & 10M & $r=0.08$, $\sigma=0.2$, $T=1$ \\
\bottomrule
\end{tabular}
\end{table}

\vspace{-4pt}
\noindent Create separate configurations for each dimension:
\vspace{-2pt}
\begin{lstlisting}[language=Python]
# In optimal_stopping/run/configs.py

table_dim_d1 = _DefaultConfig(
    algos=['RT', 'RLSM', 'LSM', 'DOS', 'NLSM', 'EOP'],
    payoffs=['BasketCall'],
    stock_models=['UserData'],
    user_data_file='BS_1.h5',
    nb_stocks=[1],
    nb_paths=[8000000],
    nb_dates=[100],
    nb_runs=5,
    drift=[0.08],
    volatilities=[0.2],
    spots=[100],
    strikes=[100],
    maturities=[1.0],
    hidden_size=[None],  # Uses heuristic
    activation=['leakyrelu'],
    use_payoff_as_input=[True],
    dtype=['float32'],
)

table_dim_d2 = _DefaultConfig(
    algos=['RT', 'RLSM', 'LSM', 'DOS', 'NLSM', 'EOP'],
    payoffs=['BasketCall'],
    stock_models=['UserData'],
    user_data_file='BS_2.h5',
    nb_stocks=[2],
    nb_paths=[8000000],
    nb_dates=[100],
    nb_runs=5,
    # ... same market parameters ...
)

# Similarly for d=7, d=50, d=500 with corresponding files
\end{lstlisting}

\vspace{-2pt}
\noindent Execute all configurations:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.run_algo \
    --configs=table_dim_d1,table_dim_d2,table_dim_d7,table_dim_d50,table_dim_d500

python -m optimal_stopping.run.write_excel \
    --configs=table_dim_d1,table_dim_d2,table_dim_d7,table_dim_d50,table_dim_d500
\end{lstlisting}

\section{Example Configurations}
\label{sec:examples}
\vspace{-4pt}

This section provides ready-to-use configurations for common experimental scenarios.

\subsection{Fresh Black-Scholes Paths}
\vspace{-4pt}

Run experiments with freshly generated GBM paths (no stored data required):
\vspace{-2pt}
\begin{lstlisting}[language=Python]
fresh_bs_experiment = _DefaultConfig(
    algos=['RT', 'RLSM'],
    payoffs=['BasketCall', 'MaxCall'],
    stock_models=['BlackScholes'],
    nb_stocks=[5, 25, 50],
    nb_paths=[1000000],
    nb_dates=[100],
    nb_runs=3,
    drift=[0.05],
    volatilities=[0.2],
    correlation=[0.0],
    spots=[100],
    strikes=[100],
    maturities=[1.0],
)
\end{lstlisting}

\subsection{Real Market Data (Stationary Block Bootstrap)}
\vspace{-4pt}

Validate algorithms using historical S\&P 500 data:
\vspace{-2pt}
\begin{lstlisting}[language=Python]
real_data_experiment = _DefaultConfig(
    algos=['RT', 'RLSM'],
    payoffs=['BasketCall', 'BasketPut', 'MaxCall'],
    stock_models=['RealData'],
    nb_stocks=[5, 10, 25],
    nb_paths=[500000],
    nb_dates=[50],
    nb_runs=3,
    maturities=[0.5],
    spots=[100],
    strikes=[90, 100, 110],
)
\end{lstlisting}

\vspace{-4pt}
\noindent The \texttt{RealData} model automatically downloads historical data from Yahoo Finance and applies stationary block bootstrap to generate paths.

\subsection{Barrier Options}
\vspace{-4pt}

Configure single and double barrier options:
\vspace{-2pt}
\begin{lstlisting}[language=Python]
# Single barrier (Up-and-Out, Down-and-In)
single_barrier_exp = _DefaultConfig(
    algos=['RT', 'SRLSM'],
    payoffs=['UO-BasketCall', 'DI-MaxCall'],
    stock_models=['BlackScholes'],
    nb_stocks=[5, 25],
    barriers=[120],  # Single barrier level B
    spots=[100],
    strikes=[100],
)

# Double barrier (Up-Out-Down-Out)
double_barrier_exp = _DefaultConfig(
    algos=['RT', 'SRLSM'],
    payoffs=['UODO-BasketCall', 'UIDI-MinPut'],
    stock_models=['BlackScholes'],
    nb_stocks=[5, 25],
    barriers_up=[150],   # Upper barrier B_U
    barriers_down=[70],  # Lower barrier B_L
    spots=[100],
    strikes=[100],
)
\end{lstlisting}

\subsection{Path-Dependent Options}
\vspace{-4pt}

Configure Asian and lookback options:
\vspace{-2pt}
\begin{lstlisting}[language=Python]
path_dependent_exp = _DefaultConfig(
    algos=['RT', 'RRLSM'],
    payoffs=[
        'LookbackFixedCall',
        'LookbackFloatPut',
        'AsianFixedStrikeCall',
        'AsianFloatingStrikePut',
    ],
    stock_models=['BlackScholes'],
    nb_stocks=[1, 5, 25],
    nb_paths=[2000000],
    nb_dates=[50],
    activation=['elu'],  # ELU recommended for path-dependent
    use_path=[True],
)
\end{lstlisting}

\subsection{Heston Stochastic Volatility}
\vspace{-4pt}
\begin{lstlisting}[language=Python]
heston_experiment = _DefaultConfig(
    algos=['RT', 'RLSM'],
    payoffs=['BasketCall'],
    stock_models=['Heston'],
    nb_stocks=[5, 25],
    drift=[0.05],
    volatilities=[0.2],      # Initial volatility sqrt(v_0)
    mean=[0.04],             # Long-run variance theta
    speed=[2.0],             # Mean reversion kappa
    correlation=[-0.7],      # Leverage effect rho
)
\end{lstlisting}

\subsection{Rough Heston}
\vspace{-4pt}

\noindent\textbf{Note:} Rough Heston path generation is computationally expensive. It is strongly recommended to use stored paths (see Section~\ref{sec:store-paths}).
\vspace{-2pt}
\begin{lstlisting}[language=Python]
rough_heston_experiment = _DefaultConfig(
    algos=['RT', 'RLSM'],
    payoffs=['BasketCall'],
    stock_models=['RoughHeston'],
    nb_stocks=[5],
    hurst=[0.1],             # Roughness parameter H
    mean=[0.3],              # theta
    speed=[0.15],            # kappa
    correlation=[-0.7],      # rho
    nb_paths=[100000],       # Reduced due to slow generation
)
\end{lstlisting}

\section{Additional Functionalities}
\label{sec:functionalities}
\vspace{-4pt}

The framework provides several additional tools for analysis and visualization.

\subsection{Convergence Plots}
\vspace{-4pt}

Generate plots showing how option prices converge with respect to a varying parameter:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.plot_convergence --configs=my_experiment
\end{lstlisting}

\vspace{-4pt}
\noindent This produces publication-quality figures with:
\begin{itemize}
    \setlength{\itemsep}{1pt}
    \item Price convergence over Monte Carlo paths
    \item 95\% confidence intervals (t-distribution)
    \item Algorithm comparison across dimensions
\end{itemize}

\subsection{Exercise Policy Videos}
\vspace{-4pt}

Create animated visualizations of optimal exercise decisions:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.create_video \
    --config=my_experiment \
    --nb_paths_to_plot=100
\end{lstlisting}

\vspace{-4pt}
\noindent The video shows:
\begin{itemize}
    \setlength{\itemsep}{1pt}
    \item Stock price paths evolving over time
    \item Exercise decisions marked with red dots
    \item Paths grayed out after exercise
    \item Running statistics and payoff evolution
\end{itemize}

\subsection{Store Paths for Reproducibility}
\label{sec:store-paths}
\vspace{-4pt}

Pre-generate and store paths for exact reproducibility, particularly important for slow models like Rough Heston:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
# Store RealData paths
python -m optimal_stopping.data.store_paths \
    --stock_model=RealData \
    --nb_stocks=50 \
    --nb_paths=100000 \
    --nb_dates=252 \
    --maturity=1.0

# Store Rough Heston paths (slow, do once)
python -m optimal_stopping.data.store_paths \
    --stock_model=RoughHeston \
    --nb_stocks=5 \
    --nb_paths=100000 \
    --nb_dates=100 \
    --maturity=1.0 \
    --hurst=0.1

# List stored paths
python -m optimal_stopping.data.store_paths --list
\end{lstlisting}

\vspace{-4pt}
\noindent Use stored paths in configurations:
\vspace{-2pt}
\begin{lstlisting}[language=Python]
stored_paths_exp = _DefaultConfig(
    stock_models=['RealDataStored1732000000123'],  # Use storage ID
    nb_stocks=[10],      # Can use subset
    nb_paths=[50000],    # Can use subset
    nb_dates=[252],      # Must match exactly
    maturities=[1.0],    # Must match exactly
    spots=[90, 100],     # Can rescale
)
\end{lstlisting}

\subsection{Results to Excel}
\vspace{-4pt}

Aggregate raw CSV results into formatted Excel files:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.write_excel --configs=my_experiment
\end{lstlisting}

\vspace{-4pt}
\noindent Output file \texttt{my\_experiment\_summary.xlsx} contains:
\begin{itemize}
    \setlength{\itemsep}{1pt}
    \item Mean prices per configuration
    \item Standard deviations and confidence intervals
    \item Execution times
    \item Relative errors (when benchmark available)
\end{itemize}

\subsection{Paper-Quality Figures}
\vspace{-4pt}

Generate publication-ready figures and compile to PDF:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.write_figures --configs=my_experiment
\end{lstlisting}

\section{Hyperparameter Optimization}
\label{sec:hyperopt}
\vspace{-4pt}

The framework includes Bayesian hyperparameter optimization via Optuna. Table~\ref{tab:hyperopt-params} summarizes the optimization parameters.

\vspace{-4pt}
\begin{table}[htbp]
\centering
\caption{Hyperparameter optimization configuration.}
\label{tab:hyperopt-params}
\vspace{-4pt}
\small
\begin{tabular}{llll}
\toprule
\textbf{Parameter} & \textbf{Type} & \textbf{Default} & \textbf{Description} \\
\midrule
\texttt{enable\_hyperopt} & \texttt{bool} & \texttt{False} & Enable optimization \\
\texttt{hyperopt\_method} & \texttt{str} & \texttt{'tpe'} & \texttt{'tpe'} or \texttt{'random'} \\
\texttt{hyperopt\_timeout} & \texttt{float} & \texttt{1200} & Timeout (seconds) \\
\texttt{hyperopt\_n\_trials} & \texttt{int} & \texttt{None} & Max trials (\texttt{None} = timeout) \\
\texttt{hyperopt\_fidelity\_factor} & \texttt{int} & \texttt{4} & Use $m/4$ paths \\
\texttt{hyperopt\_variance\_penalty} & \texttt{float} & \texttt{0.1} & Variance penalty $\lambda$ \\
\texttt{hyperopt\_output\_dir} & \texttt{str} & \texttt{'hyperopt\_results'} & Output directory \\
\bottomrule
\end{tabular}
\end{table}

\vspace{-4pt}
\noindent Configure and run hyperparameter optimization:
\vspace{-2pt}
\begin{lstlisting}[language=Python]
hpo_experiment = _DefaultConfig(
    algos=['RT'],
    payoffs=['BasketCall'],
    stock_models=['BlackScholes'],
    nb_stocks=[50],
    nb_paths=[1000000],

    # Enable hyperparameter optimization
    enable_hyperopt=True,
    hyperopt_method='tpe',          # Bayesian optimization
    hyperopt_timeout=3600,          # 1 hour
    hyperopt_n_trials=100,
    hyperopt_fidelity_factor=4,     # Use 1/4 of paths
    hyperopt_variance_penalty=0.1,
)
\end{lstlisting}

\vspace{-2pt}
\noindent Execute optimization:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.run_hyperopt --configs=hpo_experiment
\end{lstlisting}

\section{Troubleshooting}
\label{sec:troubleshooting}

\subsection{Memory Issues}
\vspace{-4pt}

For high-dimensional problems ($d \geq 100$) or large path counts ($m \geq 10^7$):
\vspace{-2pt}
\begin{lstlisting}[language=Python]
memory_efficient_exp = _DefaultConfig(
    dtype=['float32'],           # Use single precision
    nb_paths=[1000000],          # Reduce path count
)
\end{lstlisting}

\vspace{-4pt}
\noindent Reduce parallelism:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.run_algo --configs=exp --nb_jobs=4
\end{lstlisting}

\subsection{Algorithm Not Found}
\vspace{-4pt}

Algorithm names are case-sensitive:
\vspace{-2pt}
\begin{lstlisting}[language=Python]
algos=['RT', 'RLSM', 'LSM']  # Correct
algos=['rt', 'rlsm', 'lsm']  # Incorrect
\end{lstlisting}

\subsection{Reproducibility}
\vspace{-4pt}

For exact reproducibility across runs:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
python -m optimal_stopping.run.run_algo --configs=exp --path_gen_seed=42
\end{lstlisting}

\subsection{Slow Path Generation}
\vspace{-4pt}

For computationally expensive models (Rough Heston, RealData), store paths once and reuse:
\vspace{-2pt}
\begin{lstlisting}[language=bash]
# Generate once
python -m optimal_stopping.data.store_paths --stock_model=RoughHeston ...

# Reuse in experiments
stock_models=['RoughHestonStored{ID}']
\end{lstlisting}

\section{Summary}
\label{sec:summary}
\vspace{-4pt}

The \texttt{optimal\_stopping} framework provides complete infrastructure for American option pricing research. Key usage patterns:
\vspace{-4pt}
\begin{enumerate}
    \setlength{\itemsep}{1pt}
    \item Define configuration: \texttt{my\_exp = \_DefaultConfig(...)}
    \item Execute: \texttt{python -m optimal\_stopping.run.run\_algo --configs=my\_exp}
    \item Aggregate: \texttt{python -m optimal\_stopping.run.write\_excel --configs=my\_exp}
    \item Visualize: \texttt{python -m optimal\_stopping.run.plot\_convergence --configs=my\_exp}
    \item Analyze results in \texttt{results/my\_exp/}
\end{enumerate}

\vspace{-2pt}
\noindent For questions or issues, consult the repository documentation or open an issue on GitHub.
