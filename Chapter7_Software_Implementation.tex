\chapter{Software Implementation}
\label{ch:software_implementation}

\noindent A central contribution of this research is an open-source, reproducible software framework for American option pricing. The full implementation, including the nine algorithms used throughout the thesis, a comprehensive payoff library, and experimental infrastructure, is publicly available at:
\begin{center}
\url{https://github.com/Daniel-Souza7/thesis-new-files}
\end{center}
The framework emphasizes modularity, extensibility and efficiency enabling systematic experimentation. Furthermore, a manual containing instructions for software utilization is provided in Appendix~\ref{att:setup_guide}.

\section{Software Framework Overview}
\label{sec:framework_overview}

The \texttt{optimal\_stopping} Python repository implements a production-grade computational environment for large-scale American option pricing benchmarks. The modular architecture organizes functionality across five core directories, each encapsulating distinct aspects of the pricing workflow.

\vspace{0.3cm}

\noindent \textbf{Algorithms Module (\texttt{algorithms/}):} Contains implementations of all nine methods evaluated in Chapter~\ref{ch:results}, organized into standard variants (RLSM, RFQI, LSM, FQI, NLSM, DOS, EOP) and path-dependent extensions (SRLSM, SRFQI, RRLSM). Each algorithm supports configurable activation functions (ReLU, LeakyReLU, ELU, Tanh), parameterized hidden layer sizes, and dropout regularization. The factory pattern enables dynamic instantiation via string identifiers specified in configuration files.

\vspace{0.3cm}

\noindent \textbf{Payoffs Module (\texttt{payoffs/}):} Implements the 360-instrument library documented in Section~\ref{sec:payoffs} through combinatorial construction of 30 base payoff functionals and 12 barrier conditions. The automated registration system via \texttt{\_\_init\_subclass\_\_} metaclass hooks enables new derivatives to be defined through simple class inheritance without manual registry modifications. Complete mathematical specifications are provided in \texttt{payoffs\_index.tex}.

\vspace{0.3cm}

\noindent \textbf{Data Module (\texttt{data/}):} Houses implementations of the five stochastic processes detailed in Section~\ref{sec:underlying_processes}: Geometric Brownian Motion with configurable correlation matrices, Heston stochastic volatility, Fractional Brownian Motion, Rough Heston, and the Stationary Block Bootstrap empirical model interfacing with Yahoo Finance via \texttt{yfinance} or custom CSV data. The path storage subsystem (\texttt{store\_paths.py}) serializes generated trajectories to compressed HDF5 archives, enabling pre-computation and reuse across experiments as demonstrated in Section~\ref{subsec:simulation_protocol}. Users can generate and store custom path sets or download the datasets used throughout this thesis from the \href{https://drive.google.com/drive/folders/1QVHAzgOZjcE3zN3rTba81LQ-GmGk5wWx?usp=sharing}{public repository}, referencing them via dataset identifiers in \texttt{configs.py}.

\vspace{0.3cm}

\noindent \textbf{Execution Module (\texttt{run/}):} Orchestrates the experimental workflow through specialized scripts. The \texttt{run\_algo.py} harness executes algorithm benchmarks with multiprocessing support and optional Telegram notifications upon completion. Results aggregation is handled by \texttt{write\_excel.py}, which processes large CSV outputs into structured spreadsheets with summary statistics, formatted execution times, and configuration metadata. Convergence diagnostics are generated via \texttt{plot\_convergence.py}, producing visualizations with $t$-distribution confidence intervals. Exercise decision analysis is performed by \texttt{create\_video.py}, which renders animated trajectories illustrating stopping policies. The comprehensive configuration system (\texttt{configs.py}) specifies all experimental parameters declaratively, supporting parameter sweeps via iterables for systematic sensitivity analysis.

\vspace{0.3cm}

\noindent \textbf{Optimization Module (\texttt{optimization/}):} Provides Bayesian hyperparameter tuning infrastructure via Optuna \cite{akiba2019optuna}, implementing Tree-structured Parzen Estimator search with multi-fidelity evaluation. The module supports automatic parameter space exploration for algorithm-specific configurations (hidden layer dimensions, activation functions, regularization coefficients) with full trial logging and visualization generation. Execution is managed through \texttt{run\_hyperopt.py}.

\section{Development Credits and Contributions}
\label{sec:credits}

This work builds upon the repository of Herrera et al.\ \cite{herrera2021optimal} (\url{https://github.com/HeKrRuTe/OptStopRandNN}), which was modernized as part of the contributions of this thesis. The original codebase was migrated to contemporary Python environments and package ecosystems, resolving deprecated dependencies that precluded execution on modern systems. The foundational algorithmic implementations (RLSM, RRLSM, RFQI) and initial stochastic model classes (BlackScholes, Heston, FractionalBrownianMotion) from the original repository were retained, with the BlackScholes model extended to support configurable correlation matrices for multi-asset simulations.

\vspace{0.3cm}

\noindent Significant architectural enhancements were developed as part of this thesis. The RT algorithm and its associated dimension-adaptive heuristics (Equation~\eqref{eq:neuron_heuristic}) were implemented, incorporating payoff augmentation, non-negativity constraints, and precision management. Additional benchmark algorithms (LSM, FQI, NLSM, DOS) were integrated from alternative implementations to enable comprehensive comparative analysis. The activation function framework was extended to support parameterized selection (ReLU, LeakyReLU, ELU, Tanh) across all randomized neural network variants. Exercise time extraction functionality was developed to enable policy visualization and algorithmic debugging, facilitating the identification and correction of spurious early exercise behaviors documented in Section~\ref{subsec:structural_enhancements}.

\vspace{0.3cm}

\noindent The payoff library underwent complete restructuring. The original implementation supporting eight fixed derivatives was replaced with the combinatorial 360-instrument framework detailed in Section~\ref{sec:payoffs}, leveraging automated registration patterns to minimize maintenance overhead. The Stationary Block Bootstrap model with Yahoo Finance integration was implemented to enable empirical validation against historical market data. Path storage and retrieval infrastructure (\texttt{store\_paths.py}) was developed to eliminate redundant Monte Carlo simulation across experimental trials.

\vspace{0.3cm}

\noindent Results processing and visualization capabilities were substantially expanded. The \texttt{write\_excel.py} aggregation pipeline was created to handle large-scale benchmark outputs, computing cross-run statistics and organizing results hierarchically. Convergence analysis (\texttt{plot\_convergence.py}) and exercise policy animation (\texttt{create\_video.py}) tools were developed to produce the diagnostic visualizations presented throughout Chapter~\ref{ch:results}. The table generation subsystem (\texttt{comparison\_table.py}) was reimplemented to correct rendering issues in the original LaTeX export functionality. Execution time instrumentation was integrated across all algorithmic modules to support the efficiency comparisons in Section~\ref{sec:curse_dimensionality}. Telegram notification functionality, adapted from the implementation by Florian Ofenheimer-Krach (\url{https://github.com/FlorianKrach/Telegram-Bot-Install}), was incorporated to facilitate asynchronous monitoring of long-running experiments.

\vspace{0.3cm}

\noindent The hyperparameter optimization infrastructure (\texttt{optimization/}) represents an original contribution, implementing multi-fidelity Bayesian search with automatic trial management and result logging. This subsystem supports ongoing research into problem-specific hyperparameter selection strategies beyond the scope of this thesis.

\vspace{0.3cm}

\noindent While the original repository provided an essential foundation, substantial engineering effort was required to transform it into the production-grade research platform documented herein. The combination of modernization, algorithmic enhancement, architectural expansion, and tooling development collectively enabled the comprehensive empirical evaluation presented in Chapter~\ref{ch:results}.

\section{Interactive Optimal Stopping Game}
\label{sec:pricing_game}


